"""
Analysis Report Functions
Author: User 67991023, Current Date: 2025-09-02 06:47:37
"""

import os
from typing import Dict, List
import datetime
import pandas as pd
import numpy as np
from config import APP_CONFIG, FILE_CONFIG

def generate_basic_summary(voice_records: List[Dict]) -> str:
    """Generate basic analysis summary"""
    from Thai_textProcessing import fix_thai_word_count
    from dataManagement import get_data_statistics
    
    if not voice_records:
        return "âŒ No data available for analysis"
    
    try:
        # Get statistics
        stats = get_data_statistics(voice_records)
        
        # Basic analysis
        dates = list(set([r.get('date', '') for r in voice_records if r.get('date')]))
        dates = [d for d in dates if d]
        
        summary = f"""
ğŸ“Š VOICE RECORDING ANALYSIS SUMMARY
{'=' * 50}
ğŸ‘¤ User: {APP_CONFIG['user_login']}
ğŸ“… Analysis Date: {APP_CONFIG['current_datetime']}
ğŸ”– Version: {APP_CONFIG['version']}

ğŸ“ˆ DATASET OVERVIEW
â€¢ Total Recordings: {stats['total_records']:,}
â€¢ Recording Period: {len(dates)} day(s)

ğŸ“Š WORD ANALYSIS
â€¢ Total Words: {stats['word_statistics']['total_words']:,}
â€¢ Average Words/Recording: {stats['word_statistics']['mean_words']:.1f}
â€¢ Range: {stats['word_statistics']['min_words']} - {stats['word_statistics']['max_words']} words

ğŸ“‹ QUALITY METRICS
â€¢ Short Recordings (â‰¤5 words): {sum(1 for r in voice_records if r.get('word_count', 0) <= 5)}
â€¢ Medium Recordings (6-20 words): {sum(1 for r in voice_records if 6 <= r.get('word_count', 0) <= 20)}
â€¢ Long Recordings (>20 words): {sum(1 for r in voice_records if r.get('word_count', 0) > 20)}

ğŸ”§ TECHNICAL INFO
â€¢ Analysis Method: Statistical Computing + ML Classification
â€¢ Word Counting: {'Thai Tokenization (pythainlp)' if 'pythainlp' in str(type(fix_thai_word_count)) else 'Estimation Method'}
â€¢ Libraries: NumPy, Pandas, Matplotlib, Scikit-learn
â€¢ Data Quality: Validated and processed

{'=' * 50}
Generated: {APP_CONFIG['current_datetime']}
User: {APP_CONFIG['user_login']}
"""
        
        return summary
        
    except Exception as e:
        return f"âŒ Error generating summary: {e}"

def generate_ml_analysis_report(results_df: pd.DataFrame) -> str:
    """Generate comprehensive ML analysis report"""
    if results_df.empty:
        return "âŒ No ML results available for analysis"
    
    try:
        # Extract metadata
        silhouette_score = results_df.attrs.get('silhouette_score', 0.0)
        cluster_keywords = results_df.attrs.get('cluster_keywords', {})
        n_features = results_df.attrs.get('n_features', 0)
        
        # Calculate statistics
        total_records = len(results_df)
        n_clusters = len(results_df['ml_cluster'].unique()) if 'ml_cluster' in results_df.columns else 0
        n_categories = len(results_df['rule_category'].unique()) if 'rule_category' in results_df.columns else 0
        
        # Word statistics
        word_mean = results_df['word_count'].mean()
        word_std = results_df['word_count'].std()
        
        # Cluster analysis
        cluster_info = ""
        if 'ml_cluster' in results_df.columns:
            for cluster_id in sorted(results_df['ml_cluster'].unique()):
                cluster_data = results_df[results_df['ml_cluster'] == cluster_id]
                cluster_size = len(cluster_data)
                cluster_mean_words = cluster_data['word_count'].mean()
                
                keywords = cluster_keywords.get(cluster_id, [])
                keywords_str = ', '.join(keywords[:3]) if keywords else "N/A"
                
                cluster_info += f"""
  ğŸ·ï¸ Cluster {cluster_id}: {cluster_size} records ({cluster_size/total_records*100:.1f}%)
     â€¢ Avg Words: {cluster_mean_words:.1f}
     â€¢ Keywords: {keywords_str}"""
        
        # Category analysis
        category_info = ""
        if 'rule_category' in results_df.columns:
            category_counts = results_df['rule_category'].value_counts()
            for category, count in category_counts.head(5).items():
                category_info += f"""
  ğŸ“‚ {category}: {count} records ({count/total_records*100:.1f}%)"""
        
        report = f"""
ğŸ¤– MACHINE LEARNING ANALYSIS REPORT
{'=' * 55}

ğŸ“Š DATASET ANALYSIS
â€¢ Total Records Processed: {total_records:,}
â€¢ ML Features Generated: {n_features}
â€¢ Average Words per Record: {word_mean:.1f} Â± {word_std:.1f}

ğŸ§  CLUSTERING RESULTS
â€¢ Number of Clusters: {n_clusters}
â€¢ Clustering Quality (Silhouette): {silhouette_score:.3f}
â€¢ Cluster Performance: {'Good' if silhouette_score > 0.3 else 'Moderate' if silhouette_score > 0.1 else 'Poor'}
{cluster_info}

ğŸ“‚ RULE-BASED CLASSIFICATION
â€¢ Number of Categories: {n_categories}
{category_info}

ğŸ“ˆ INSIGHTS & RECOMMENDATIONS
â€¢ Data Quality: {'Excellent' if word_mean > 10 else 'Good' if word_mean > 5 else 'Needs Improvement'}
â€¢ Cluster Separation: {'Well-separated' if silhouette_score > 0.3 else 'Moderately separated' if silhouette_score > 0.1 else 'Overlapping'}
â€¢ Dataset Size: {'Adequate for ML' if total_records >= 10 else 'Small - consider collecting more data'}

{'=' * 55}
Generated: {APP_CONFIG['current_datetime']}
User: {APP_CONFIG['user_login']}
ML Analysis Version: {APP_CONFIG['version']}
"""
        
        return report
        
    except Exception as e:
        return f"âŒ Error generating ML report: {e}"

def save_analysis_report(report_content: str, report_type: str = "basic") -> str:
    """Save analysis report to file"""
    os.makedirs(FILE_CONFIG['output_dir'], exist_ok=True)
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{report_type}_analysis_report_{timestamp}.txt"
    output_path = os.path.join(FILE_CONFIG['output_dir'], filename)
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“‹ Report saved: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"âŒ Error saving report: {e}")
        return ""

def create_project_summary(voice_records: List[Dict], results_df: pd.DataFrame = None) -> str:
    """Create comprehensive project summary"""
    try:
        # Get basic statistics
        from dataManagement import get_data_statistics
        summary_stats = get_data_statistics(voice_records) if voice_records else {}
        
        presentation = f"""
ğŸ¯ THAI VOICE RECORDER PROJECT SUMMARY
{'=' * 55}

ğŸ“‹ PROJECT OVERVIEW
This project implements an advanced Thai voice recording system with integrated 
machine learning analytics for text classification and data visualization.

ğŸ¯ OBJECTIVES ACHIEVED
âœ… Real-time Thai voice recording and transcription
âœ… Automated text processing and word counting
âœ… Machine learning classification (TF-IDF + K-Means)
âœ… Comprehensive data visualization and reporting tools
âœ… Statistical analysis of voice recording patterns

ğŸ“š LIBRARIES/MODULES USED
âœ… NumPy: Advanced statistical calculations and array operations
âœ… Pandas: Data manipulation, aggregation, and DataFrame operations  
âœ… Matplotlib: Data visualization, charts, and statistical plots
âœ… Scikit-learn: TF-IDF vectorization, K-Means clustering, ML metrics

ğŸ“Š NATURE OF DATA
â€¢ Voice Records: {summary_stats.get('total_records', 0)} Thai language recordings
â€¢ Text Data: Transcribed speech with word/character counts
â€¢ Metadata: User info, session data, categories, ML features
â€¢ Statistical Data: Word distributions, cluster assignments

âš™ï¸ METHODOLOGY
1. ğŸ™ï¸ Voice Recording â†’ Speech Recognition (Google API)
2. ğŸ“ Text Processing â†’ Thai tokenization (pythainlp)
3. ğŸ¤– ML Classification â†’ TF-IDF â†’ K-Means Clustering
4. ğŸ“Š Visualization â†’ Matplotlib charts + statistical reports
5. ğŸ“‹ Analysis â†’ Comprehensive reporting system

ğŸ“ˆ RESULTS/OUTPUT"""
        
        # Add results based on available data
        if summary_stats.get('word_statistics'):
            word_stats = summary_stats['word_statistics']
            presentation += f"""

ğŸ“ Word Analysis Results:
â€¢ Total Words Processed: {word_stats['total_words']:,}
â€¢ Average Words per Recording: {word_stats['mean_words']:.1f}
â€¢ Word Count Range: {word_stats['min_words']} - {word_stats['max_words']}"""
        
        if results_df is not None and not results_df.empty:
            ml_clusters = len(results_df['ml_cluster'].unique()) if 'ml_cluster' in results_df.columns else 0
            rule_categories = len(results_df['rule_category'].unique()) if 'rule_category' in results_df.columns else 0
            
            presentation += f"""

ğŸ¤– Machine Learning Results:
â€¢ ML Clusters Identified: {ml_clusters}
â€¢ Rule-based Categories: {rule_categories}"""
            
            if hasattr(results_df, 'attrs') and 'silhouette_score' in results_df.attrs:
                silhouette = results_df.attrs['silhouette_score']
                presentation += f"â€¢ Clustering Quality (Silhouette): {silhouette:.3f}\n"
        
        presentation += f"""

ğŸ’» IMPLEMENTATION
â€¢ Programming Language: Python 3.x
â€¢ Architecture: Modular design with separated functions
â€¢ Voice Processing: SpeechRecognition + pyttsx3
â€¢ Data Storage: JSON with backup system
â€¢ Analytics Pipeline: Integrated ML and statistical analysis
â€¢ User Interface: Interactive command-line interface

ğŸ“š REFERENCES
â€¢ Scikit-learn Documentation: Machine Learning algorithms
â€¢ Matplotlib Documentation: Data visualization techniques
â€¢ Pandas Documentation: Data manipulation and analysis
â€¢ NumPy Documentation: Numerical computing foundations
â€¢ pythainlp Documentation: Thai natural language processing

ğŸ¯ PROJECT ACHIEVEMENTS
âœ… Successfully implemented Thai voice recording system
âœ… Developed ML text classification with {f"{len(results_df['ml_cluster'].unique())} clusters" if results_df is not None and not results_df.empty else "clustering capabilities"}
âœ… Created comprehensive data visualization tools
âœ… Generated automated analysis reports
âœ… Achieved modular, maintainable code architecture

ğŸ“Š STATISTICAL SUMMARY
â€¢ Dataset Size: {summary_stats.get('total_records', 0)} recordings
â€¢ Quality Distribution:
  - Short (â‰¤5 words): {sum(1 for r in voice_records if r.get('word_count', 0) <= 5) if voice_records else 0}
  - Medium (6-20 words): {sum(1 for r in voice_records if 6 <= r.get('word_count', 0) <= 20) if voice_records else 0}
  - Long (>20 words): {sum(1 for r in voice_records if r.get('word_count', 0) > 20) if voice_records else 0}

ğŸ† CONCLUSION
This project successfully demonstrates the integration of voice recording 
technology with machine learning analytics, providing comprehensive insights 
through text classification and statistical analysis.

{'=' * 55}
Generated: {APP_CONFIG['current_datetime']}
Project completed by User: {APP_CONFIG['user_login']}
"""
    
        return presentation
        
    except Exception as e:
        return f"âŒ Error generating project summary: {e}"